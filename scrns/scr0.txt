transpose/perm: (Const): /job:localhost/replica:0/task:0/device:CPU:0
2020-10-01 15:16:37.882701: I tensorflow/core/common_runtime/placer.cc:874] transpose/perm: (Const)/job:localhost/replica:0/task:0/device:CPU:0
PERFORMANCE ON TEST SET: Batch Loss = 2.9903688430786133, Accuracy = 0.12012215703725815
Training iter #30000:   Batch Loss = 1.764793, Accuracy = 0.5960000157356262
PERFORMANCE ON TEST SET: Batch Loss = 1.808652400970459, Accuracy = 0.5341024994850159
Training iter #60000:   Batch Loss = 1.249496, Accuracy = 0.7193333506584167
PERFORMANCE ON TEST SET: Batch Loss = 1.3611714839935303, Accuracy = 0.6823888421058655
Training iter #90000:   Batch Loss = 1.075620, Accuracy = 0.8266666531562805
PERFORMANCE ON TEST SET: Batch Loss = 1.2708888053894043, Accuracy = 0.7587376832962036
Training iter #120000:   Batch Loss = 0.810687, Accuracy = 0.9233333468437195
PERFORMANCE ON TEST SET: Batch Loss = 1.1647396087646484, Accuracy = 0.8048863410949707
Training iter #150000:   Batch Loss = 0.754318, Accuracy = 0.9286666512489319
PERFORMANCE ON TEST SET: Batch Loss = 1.1765153408050537, Accuracy = 0.8194774389266968
Training iter #180000:   Batch Loss = 0.811084, Accuracy = 0.8820000290870667
PERFORMANCE ON TEST SET: Batch Loss = 1.1110442876815796, Accuracy = 0.8442484140396118
Training iter #210000:   Batch Loss = 0.744253, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 1.0808285474777222, Accuracy = 0.8595181703567505
Training iter #240000:   Batch Loss = 0.634803, Accuracy = 0.9580000042915344
PERFORMANCE ON TEST SET: Batch Loss = 1.022623062133789, Accuracy = 0.8727519512176514
Training iter #270000:   Batch Loss = 0.633416, Accuracy = 0.9520000219345093
PERFORMANCE ON TEST SET: Batch Loss = 0.9741290807723999, Accuracy = 0.8615541458129883
Training iter #300000:   Batch Loss = 0.583558, Accuracy = 0.984666645526886
PERFORMANCE ON TEST SET: Batch Loss = 0.9757859706878662, Accuracy = 0.8758059144020081
Training iter #330000:   Batch Loss = 0.623075, Accuracy = 0.9753333330154419
PERFORMANCE ON TEST SET: Batch Loss = 0.9651765823364258, Accuracy = 0.8842890858650208
Training iter #360000:   Batch Loss = 0.629927, Accuracy = 0.9573333263397217
PERFORMANCE ON TEST SET: Batch Loss = 0.9532959461212158, Accuracy = 0.8863250613212585
Training iter #390000:   Batch Loss = 0.639751, Accuracy = 0.9393333196640015
PERFORMANCE ON TEST SET: Batch Loss = 0.9604495763778687, Accuracy = 0.879199206829071
Training iter #420000:   Batch Loss = 0.572969, Accuracy = 0.95333331823349
PERFORMANCE ON TEST SET: Batch Loss = 0.9477505683898926, Accuracy = 0.873430609703064
Training iter #450000:   Batch Loss = 0.553883, Accuracy = 0.9473333358764648
PERFORMANCE ON TEST SET: Batch Loss = 0.887812077999115, Accuracy = 0.8944689631462097
Training iter #480000:   Batch Loss = 0.675528, Accuracy = 0.9173333048820496
PERFORMANCE ON TEST SET: Batch Loss = 1.0738168954849243, Accuracy = 0.8113335371017456
Training iter #510000:   Batch Loss = 0.653265, Accuracy = 0.9353333115577698
PERFORMANCE ON TEST SET: Batch Loss = 0.8618677258491516, Accuracy = 0.8255853652954102
Training iter #540000:   Batch Loss = 0.632077, Accuracy = 0.9213333129882812
PERFORMANCE ON TEST SET: Batch Loss = 0.7701165676116943, Accuracy = 0.9060060977935791
Training iter #570000:   Batch Loss = 0.593630, Accuracy = 0.9206666946411133
PERFORMANCE ON TEST SET: Batch Loss = 0.7584496736526489, Accuracy = 0.9019341468811035
Training iter #600000:   Batch Loss = 0.576462, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 0.7497948408126831, Accuracy = 0.9087207317352295
Training iter #630000:   Batch Loss = 0.475876, Accuracy = 0.984666645526886
PERFORMANCE ON TEST SET: Batch Loss = 0.752090334892273, Accuracy = 0.9083814024925232
Training iter #660000:   Batch Loss = 0.466874, Accuracy = 0.9819999933242798
PERFORMANCE ON TEST SET: Batch Loss = 0.774101734161377, Accuracy = 0.8937903046607971
Training iter #690000:   Batch Loss = 0.450590, Accuracy = 0.9959999918937683
PERFORMANCE ON TEST SET: Batch Loss = 0.7351379990577698, Accuracy = 0.9134713411331177
Training iter #720000:   Batch Loss = 0.515107, Accuracy = 0.9520000219345093
PERFORMANCE ON TEST SET: Batch Loss = 0.732323408126831, Accuracy = 0.9090600609779358
Training iter #750000:   Batch Loss = 0.529602, Accuracy = 0.9413333535194397
PERFORMANCE ON TEST SET: Batch Loss = 0.7380253672599792, Accuracy = 0.9056667685508728
Training iter #780000:   Batch Loss = 0.460876, Accuracy = 0.9639999866485596
PERFORMANCE ON TEST SET: Batch Loss = 0.7243626117706299, Accuracy = 0.907024085521698
Training iter #810000:   Batch Loss = 0.446337, Accuracy = 0.9613333344459534
PERFORMANCE ON TEST SET: Batch Loss = 0.6907620429992676, Accuracy = 0.9212758541107178
Training iter #840000:   Batch Loss = 0.477254, Accuracy = 0.9346666932106018
PERFORMANCE ON TEST SET: Batch Loss = 0.7122087478637695, Accuracy = 0.903630793094635
Training iter #870000:   Batch Loss = 0.436009, Accuracy = 0.9580000042915344
PERFORMANCE ON TEST SET: Batch Loss = 0.7354108095169067, Accuracy = 0.8954869508743286
Training iter #900000:   Batch Loss = 0.413990, Accuracy = 0.9639999866485596
PERFORMANCE ON TEST SET: Batch Loss = 0.7460474967956543, Accuracy = 0.8944689631462097
Training iter #930000:   Batch Loss = 0.488825, Accuracy = 0.9206666946411133
PERFORMANCE ON TEST SET: Batch Loss = 0.6846957206726074, Accuracy = 0.8958262801170349
Training iter #960000:   Batch Loss = 0.458181, Accuracy = 0.9359999895095825
PERFORMANCE ON TEST SET: Batch Loss = 0.6287559866905212, Accuracy = 0.922633171081543
Training iter #990000:   Batch Loss = 0.388081, Accuracy = 0.9746666550636292
PERFORMANCE ON TEST SET: Batch Loss = 0.9149013757705688, Accuracy = 0.8601968288421631
Training iter #1020000:   Batch Loss = 0.412910, Accuracy = 0.9566666483879089
PERFORMANCE ON TEST SET: Batch Loss = 0.6910772323608398, Accuracy = 0.8897183537483215
Training iter #1050000:   Batch Loss = 0.370216, Accuracy = 0.9860000014305115
PERFORMANCE ON TEST SET: Batch Loss = 0.683958113193512, Accuracy = 0.9090600609779358
Training iter #1080000:   Batch Loss = 0.399847, Accuracy = 0.9746666550636292
PERFORMANCE ON TEST SET: Batch Loss = 0.6500692367553711, Accuracy = 0.9097387194633484
Training iter #1110000:   Batch Loss = 0.414731, Accuracy = 0.95333331823349
PERFORMANCE ON TEST SET: Batch Loss = 0.6486718654632568, Accuracy = 0.9063454270362854
Training iter #1140000:   Batch Loss = 0.423801, Accuracy = 0.937333345413208
PERFORMANCE ON TEST SET: Batch Loss = 0.7397308349609375, Accuracy = 0.8727519512176514
Training iter #1170000:   Batch Loss = 0.373168, Accuracy = 0.9559999704360962
PERFORMANCE ON TEST SET: Batch Loss = 0.6736545562744141, Accuracy = 0.8971835970878601
Training iter #1200000:   Batch Loss = 0.372419, Accuracy = 0.9586666822433472
PERFORMANCE ON TEST SET: Batch Loss = 0.684433102607727, Accuracy = 0.8866643905639648
Training iter #1230000:   Batch Loss = 0.373010, Accuracy = 0.9433333277702332
PERFORMANCE ON TEST SET: Batch Loss = 0.6221661567687988, Accuracy = 0.8995589017868042
Training iter #1260000:   Batch Loss = 0.347483, Accuracy = 0.9626666903495789
PERFORMANCE ON TEST SET: Batch Loss = 0.6063368320465088, Accuracy = 0.9053274393081665
Training iter #1290000:   Batch Loss = 0.409605, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 0.5984991788864136, Accuracy = 0.9073634147644043
Training iter #1320000:   Batch Loss = 0.386787, Accuracy = 0.940666675567627
PERFORMANCE ON TEST SET: Batch Loss = 0.6344212293624878, Accuracy = 0.88802170753479
Training iter #1350000:   Batch Loss = 0.344038, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 0.5591773390769958, Accuracy = 0.9134713411331177
Training iter #1380000:   Batch Loss = 0.309156, Accuracy = 0.987333357334137
PERFORMANCE ON TEST SET: Batch Loss = 0.5809777975082397, Accuracy = 0.907024085521698
Training iter #1410000:   Batch Loss = 0.296694, Accuracy = 0.9879999756813049
PERFORMANCE ON TEST SET: Batch Loss = 0.557308554649353, Accuracy = 0.9114353656768799
Training iter #1440000:   Batch Loss = 0.319552, Accuracy = 0.984666645526886
PERFORMANCE ON TEST SET: Batch Loss = 0.5859901905059814, Accuracy = 0.9015948176383972
Training iter #1470000:   Batch Loss = 0.673818, Accuracy = 0.8866666555404663
PERFORMANCE ON TEST SET: Batch Loss = 0.6952916383743286, Accuracy = 0.873430609703064
Training iter #1500000:   Batch Loss = 0.403945, Accuracy = 0.937333345413208
PERFORMANCE ON TEST SET: Batch Loss = 0.6868351697921753, Accuracy = 0.857821524143219
Training iter #1530000:   Batch Loss = 0.299681, Accuracy = 0.9679999947547913
PERFORMANCE ON TEST SET: Batch Loss = 0.6165344715118408, Accuracy = 0.894808292388916
Training iter #1560000:   Batch Loss = 0.318244, Accuracy = 0.9566666483879089
PERFORMANCE ON TEST SET: Batch Loss = 0.6027892231941223, Accuracy = 0.8975229263305664
Training iter #1590000:   Batch Loss = 0.334380, Accuracy = 0.9433333277702332
PERFORMANCE ON TEST SET: Batch Loss = 0.6184720993041992, Accuracy = 0.894808292388916
Training iter #1620000:   Batch Loss = 0.305795, Accuracy = 0.9653333425521851
PERFORMANCE ON TEST SET: Batch Loss = 0.6167498826980591, Accuracy = 0.9019341468811035
Training iter #1650000:   Batch Loss = 0.353536, Accuracy = 0.9273333549499512
PERFORMANCE ON TEST SET: Batch Loss = 0.6227179169654846, Accuracy = 0.9005768299102783
Training iter #1680000:   Batch Loss = 0.352090, Accuracy = 0.9246666431427002
PERFORMANCE ON TEST SET: Batch Loss = 0.6446183323860168, Accuracy = 0.8965049386024475
Training iter #1710000:   Batch Loss = 0.366708, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 0.5353459715843201, Accuracy = 0.9148286581039429
Training iter #1740000:   Batch Loss = 0.275431, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 0.5740451812744141, Accuracy = 0.8961656093597412
Training iter #1770000:   Batch Loss = 0.265689, Accuracy = 0.9826666712760925
PERFORMANCE ON TEST SET: Batch Loss = 0.5824637413024902, Accuracy = 0.9009161591529846
Training iter #1800000:   Batch Loss = 0.259015, Accuracy = 0.9866666793823242
PERFORMANCE ON TEST SET: Batch Loss = 0.5612547397613525, Accuracy = 0.9060060977935791
Training iter #1830000:   Batch Loss = 0.305971, Accuracy = 0.9626666903495789
PERFORMANCE ON TEST SET: Batch Loss = 0.5755720138549805, Accuracy = 0.8975229263305664
Training iter #1860000:   Batch Loss = 0.299438, Accuracy = 0.9526666402816772
PERFORMANCE ON TEST SET: Batch Loss = 0.558956503868103, Accuracy = 0.9039701223373413
Training iter #1890000:   Batch Loss = 0.298025, Accuracy = 0.9486666917800903
PERFORMANCE ON TEST SET: Batch Loss = 0.5598145723342896, Accuracy = 0.9195792078971863
Training iter #1920000:   Batch Loss = 0.360707, Accuracy = 0.9419999718666077
PERFORMANCE ON TEST SET: Batch Loss = 0.5624415874481201, Accuracy = 0.8642687201499939
Training iter #1950000:   Batch Loss = 0.318054, Accuracy = 0.95333331823349
PERFORMANCE ON TEST SET: Batch Loss = 0.5089902877807617, Accuracy = 0.8910756707191467
Training iter #1980000:   Batch Loss = 0.310353, Accuracy = 0.9473333358764648
PERFORMANCE ON TEST SET: Batch Loss = 0.5092855095863342, Accuracy = 0.9134713411331177
Training iter #2010000:   Batch Loss = 0.277401, Accuracy = 0.9726666808128357
PERFORMANCE ON TEST SET: Batch Loss = 0.5441430807113647, Accuracy = 0.900237500667572
Training iter #2040000:   Batch Loss = 0.344647, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 0.5003836154937744, Accuracy = 0.8998982310295105
Training iter #2070000:   Batch Loss = 0.330938, Accuracy = 0.9333333373069763
PERFORMANCE ON TEST SET: Batch Loss = 0.5288214683532715, Accuracy = 0.9022734761238098
Training iter #2100000:   Batch Loss = 0.256290, Accuracy = 0.987333357334137
PERFORMANCE ON TEST SET: Batch Loss = 0.5178737640380859, Accuracy = 0.910417377948761
Training iter #2130000:   Batch Loss = 0.258264, Accuracy = 0.9853333234786987
PERFORMANCE ON TEST SET: Batch Loss = 0.5040051341056824, Accuracy = 0.9039701223373413
Training iter #2160000:   Batch Loss = 0.233415, Accuracy = 0.9826666712760925
PERFORMANCE ON TEST SET: Batch Loss = 0.4796144962310791, Accuracy = 0.9239904880523682
Training iter #2190000:   Batch Loss = 0.268961, Accuracy = 0.9706666469573975
PERFORMANCE ON TEST SET: Batch Loss = 0.5074005126953125, Accuracy = 0.9229725003242493
Optimization Finished!